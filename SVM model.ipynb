{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from joblib import dump\n",
    "import warnings\n",
    "\n",
    "# Ingore some warginigs\n",
    "warnings.filterwarnings(\"ignore\", message=\"is_sparse is deprecated\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"is_sparse is deprecated\", category=FutureWarning)\n",
    "\n",
    "file_path = r'data/Twitter_Data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop rows with missing values if any\n",
    "df.dropna(subset=['clean_text', 'category'], inplace=True)\n",
    "\n",
    "# Limit the data size\n",
    "df = df.head(160000) # remove if wanted whole dataset\n",
    "\n",
    "# Split the data into features\n",
    "X = df['clean_text']\n",
    "y = df['category']\n",
    "\n",
    "# Split the data into training and testing sets(20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorise the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=100000) #1000\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the SVM model using SGDClassifier with hinge loss function\n",
    "svm_model = SGDClassifier(loss='hinge', alpha=1e-4, max_iter=1000, tol=1e-3, n_jobs=-1, learning_rate='optimal')\n",
    "\n",
    "# Get the number of iterations for the training loop\n",
    "n_iterations = 1000 #100\n",
    "\n",
    "# Create a tqdm progress bar to track training progress (number of itterations)\n",
    "with tqdm(total=n_iterations, desc=\"Training\", unit=\"iter\", ncols=100) as pbar:\n",
    "    for i in range(n_iterations):\n",
    "        svm_model.partial_fit(X_train_vec, y_train, classes=np.unique(y_train))\n",
    "        pbar.update(1)\n",
    "\n",
    "# Predict on the testing set and evaluate the model\n",
    "y_pred = svm_model.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the trained model and vectorizer into the folder\n",
    "dump(svm_model, '160k SVM model/svm_model.joblib')\n",
    "dump(vectorizer, '160k SVM model/tfidf_vectorizer.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import load\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "stock_data = pd.read_csv('data/stock_yfinance_data.csv')\n",
    "tweets_df = pd.read_csv('data/stock_tweets.csv')\n",
    "\n",
    "svm_model = load('160k SVM model/svm_model.joblib')\n",
    "vectorizer = load('160k SVM model/tfidf_vectorizer.joblib')\n",
    "\n",
    "# Plot stock prices and weekly average sentiment over time\n",
    "def plot_stock_and_weekly_sentiment(stock_name):\n",
    "    # Filter data for the selected stock name\n",
    "    stock_data_filtered = stock_data[stock_data['Stock Name'] == stock_name].copy()\n",
    "    stock_data_filtered['Date'] = pd.to_datetime(stock_data_filtered['Date'], format='%d/%m/%Y')\n",
    "    stock_data_filtered.set_index('Date', inplace=True)\n",
    "\n",
    "    # Filter tweets for the selected stock name\n",
    "    desired_stock_tweets = tweets_df[tweets_df['Stock Name'] == stock_name]\n",
    "\n",
    "    # Do sentiment analysis with the pretrained SVM model, track with tqdm progress bar\n",
    "    sentiments = []\n",
    "    with tqdm(total=len(desired_stock_tweets), desc=\"Processing Tweets\", ncols=100) as pbar:\n",
    "        for index, row in desired_stock_tweets.iterrows():\n",
    "            tweet_vec = vectorizer.transform([row['Tweet']])\n",
    "            sentiment = svm_model.predict(tweet_vec)[0]\n",
    "            sentiments.append(sentiment)\n",
    "            pbar.update(1)\n",
    "    desired_stock_tweets['Sentiment'] = sentiments\n",
    "\n",
    "    # Convert Date column to datetime, set as index for tweets dataframe\n",
    "    desired_stock_tweets['Date'] = pd.to_datetime(desired_stock_tweets['Date'], format='%Y-%m-%d %H:%M:%S%z')\n",
    "    desired_stock_tweets.set_index('Date', inplace=True)\n",
    "\n",
    "    # Group tweets by week and calculate mean sentiment for each week\n",
    "    mean_sentiments_per_week = desired_stock_tweets.groupby(pd.Grouper(freq='W')).agg({'Sentiment': 'mean'})\n",
    "\n",
    "    # Group stock data by week and calculate mean stock price for each week\n",
    "    mean_stock_prices_per_week = stock_data_filtered['Adj Close'].resample('W').mean()\n",
    "\n",
    "    # Graphing\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot stock price\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Weekly Mean Stock Prices', color=color)\n",
    "    ax1.plot(mean_stock_prices_per_week.index, mean_stock_prices_per_week.values, color=color, linewidth=2.0, label='Weekly Mean Stock Prices')\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    # Add weekly average sentiment scores on the stock price plot\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:green'\n",
    "    ax2.set_ylabel('Weekly Mean Sentiment Score', color=color)\n",
    "    ax2.plot(mean_sentiments_per_week.index, mean_sentiments_per_week['Sentiment'], color=color, label='Weekly Mean Sentiment Score')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    # Train SVM model to predict stock prices after the red line (end date)\n",
    "    X = mean_sentiments_per_week.values.reshape(-1, 1)\n",
    "    y = mean_stock_prices_per_week.values\n",
    "\n",
    "    # Include sentiment changes from two weeks prior to red line (hotcoded supervised addition)\n",
    "    X_shifted = np.roll(X, 2)\n",
    "    X_combined = np.column_stack((X, X_shifted))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Find the index relating to the end date\n",
    "    end_date = mean_stock_prices_per_week.index.max() - pd.DateOffset(months=1)\n",
    "    intersection_index = mean_stock_prices_per_week.index.get_loc(end_date, method='nearest')\n",
    "\n",
    "    # Train SVM model on data before the red line (end date)\n",
    "    X_before_red_line = X_combined[:intersection_index]\n",
    "    y_before_red_line = y[:intersection_index]\n",
    "    svm_model_after_red_line = SVR(kernel='rbf')\n",
    "    svm_model_after_red_line.fit(X_before_red_line, y_before_red_line)\n",
    "\n",
    "    # Predict stock prices after the red line (end date)\n",
    "    predicted_stock_prices_after_red_line = svm_model_after_red_line.predict(X_combined[intersection_index:])\n",
    "\n",
    "    # Change the intercept to match the stock price at the red line (end date)\n",
    "    intercept_adjustment = mean_stock_prices_per_week.values[intersection_index] - predicted_stock_prices_after_red_line[0]\n",
    "    predicted_stock_prices_after_red_line += intercept_adjustment\n",
    "\n",
    "    # Plot the predicted stock prices after the red line (end date)\n",
    "    ax1.plot(mean_stock_prices_per_week.index[intersection_index:], predicted_stock_prices_after_red_line, color='orange', linewidth=2.0, label='Predicted Mean Weekly Stock Prices')\n",
    "\n",
    "    # Plot the red line with a dashes\n",
    "    ax1.axvline(x=mean_stock_prices_per_week.index[intersection_index], color='red', linestyle='--', linewidth=2.0, label='End Date of Model Training')\n",
    "\n",
    "    # Set graph x-axis limits (removes margins/white space)\n",
    "    ax1.set_xlim(mean_stock_prices_per_week.index[0], mean_stock_prices_per_week.index[-1])\n",
    "\n",
    "    # Combine legend for both axes\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.title(f'Stock Price and Weekly Average Sentiment for {stock_name}')\n",
    "    plt.show()\n",
    "\n",
    "# Main call function\n",
    "def main():\n",
    "    unique_stock_names = stock_data['Stock Name'].unique()\n",
    "    print(\"Possible Stock Ticker Names:\", ' '.join(unique_stock_names))\n",
    "    desired_stock_ticker = input(\"\\nEnter the name of the stock ticker you'd like to analyze: \")\n",
    "    if desired_stock_ticker not in unique_stock_names:\n",
    "        print(\"Invalid stock ticker name. Please select from the list of possible stock ticker names.\")\n",
    "        return\n",
    "    plot_stock_and_weekly_sentiment(desired_stock_ticker)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
